include Lexer
include Errors
include Parser

function generate_text(node, original_text) {
    match node.type {
        case "Program" {
            text = ""
            for node in node.body {
                text += generate_text(node, original_text)?"" + "\n"
            }
            return text
        }
        case "Operator" {
            return generate_text(node.left, original_text) + " " + node.operator + " " + generate_text(node.right, original_text)
        }
        case "NumberLiteral" {
            return String(node.value)
        }
        case "StringLiteral" {
            let quote = node.tokens.value.variation
            return quote + node.value.replace("\n", "\\n") + quote
        }
        case "VariableAccess" {
            return node.value
        }
        case "FunctionCall" {
            let object = generate_text(node.object, original_text)
            let arguments = node.arguments.map(function (x) generate_text(x, original_text))
            let keyword_arguments = node.keywordArguments.map(function(x) generate_text(x, original_text))
            let spreads = node.spreads.map(function(x) generate_text(x, original_text))
            let full_text = $"{object}({', '.join([', '.join(arguments), ', '.join(keyword_arguments), ', '.join(spreads)].filter(function(x) x != ``))})"
            return full_text
        }
        case $default {
            # stdout.write(node, "\n")
            # stdout.write(original_text.slice(node.position.start.index, node.position.end.index+1), "\n")
            return original_text.slice(node.position.start.index, node.position.end.index+1)
        }
    }
}


function format_test(text) {
    errorHandler = Errors.ErrorHandler(text, '<main>')
    lexer = Lexer.Lexer(false, false, errorHandler)
    tokens = lexer.tokenize(text)

    parser = Parser.Parser(lexer, null)
    AST = parser.parse()
    return generate_text(AST, text)
}
stdout.write(format_test("
let x=0
let y=1
stdout.write('Hello World\n')
function my_function() {
return 5
}
"), '\n')